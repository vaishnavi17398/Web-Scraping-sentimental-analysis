{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de61d8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\123.0.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\321.0.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\2345.0.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\4321.0.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\432.0.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\2893.8.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\3355.6.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\3817.4.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\4279.2.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\4741.0.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\5202.8.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\5664.6.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\6126.4.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\6588.2.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\7050.0.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\7511.8.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\7973.6.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\8435.4.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\8897.2.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\9359.0.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\9820.8.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\10282.6.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\10744.4.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\11206.2.txt\n",
      "Failed to retrieve the article at URL: https://insights.blackcoffer.com/how-neural-networks-can-be-applied-in-various-areas-in-the-future/\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\12129.8.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\12591.6.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\13053.4.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\13515.2.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\13977.0.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\14438.8.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\14900.6.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\15362.4.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\15824.2.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\16286.0.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\16747.8.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\17209.6.txt\n",
      "Failed to retrieve the article at URL: https://insights.blackcoffer.com/covid-19-environmental-impact-for-the-future/\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\18133.2.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\18595.0.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\19056.8.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\19518.6.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\19980.4.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\20442.2.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\20904.0.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\21365.8.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\21827.6.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\22289.4.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\22751.2.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\23213.0.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\23674.8.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\24136.6.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\24598.4.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\25060.2.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\25522.0.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\25983.8.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\26445.6.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\26907.4.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\27369.2.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\27831.0.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\28292.8.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\28754.6.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\29216.4.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\29678.2.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\30140.0.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\30601.8.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\31063.6.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\31525.4.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\31987.2.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\32449.0.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\32910.8.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\33372.6.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\33834.4.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\34296.2.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\34758.0.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\35219.8.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\35681.6.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\36143.4.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\36605.2.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\37067.0.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\37528.8.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\37990.6.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\38452.4.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\38914.2.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\39376.0.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\39837.8.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\40299.6.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\40761.4.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\41223.2.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\41685.0.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\42146.8.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\42608.6.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\43070.4.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\43532.2.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\43994.0.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\44455.8.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\44917.6.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\45379.4.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\45841.2.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\46303.0.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\46764.8.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\47226.6.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\47688.4.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\48150.2.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\48612.0.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\49073.8.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\49535.6.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\49997.4.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\50459.2.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\50921.0.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\51382.8.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\51844.6.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\52306.4.txt\n",
      "Article saved: C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\\52768.2.txt\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Read the Excel file with article URLs and their corresponding IDs\n",
    "input_file = \"C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/input.xlsx\"\n",
    "output_folder = \"C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\"\n",
    "\n",
    "# Create a folder to save the article texts if it doesn't exist\n",
    "import os\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "inputdf = pd.read_excel(input_file)\n",
    "\n",
    "\n",
    "\n",
    "for index, row in inputdf.iterrows():\n",
    "    url = row['URL']\n",
    "    url_id = row['URL_ID']\n",
    "\n",
    "    # Send an HTTP request to the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "    \n",
    "\n",
    "        # Find and extract the article title\n",
    "        title = soup.title.string if soup.title else \"No Title\"\n",
    "\n",
    "        # Find and extract the article text\n",
    "        \n",
    "        \n",
    "        article_text = \"\"\n",
    "        parent_div = soup.find('div', {'class': 'td-post-content tagdiv-type'})\n",
    "        \n",
    "        if parent_div:\n",
    "    # Access the <p> elements within the div\n",
    "            child_paragraphs = parent_div.find_all('p')\n",
    "        for p in child_paragraphs:\n",
    "            article_text += p.get_text() + \"\\n\"\n",
    "\n",
    "        # Save the article title and text to a text file\n",
    "        output_file = os.path.join(output_folder, f\"{url_id}.txt\")\n",
    "\n",
    "        with open(output_file, 'w', encoding='utf-8') as text_file:\n",
    "            #text_file.write(f\"Title: {title}\\n\\n\")\n",
    "            text_file.write(article_text)\n",
    "\n",
    "        print(f\"Article saved: {output_file}\")\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the article at URL: {url}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a5f9726",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vaish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import docx2txt\n",
    "import pandas as pd\n",
    "\n",
    "from textblob import TextBlob\n",
    "import os\n",
    "\n",
    "# Folder where the text files are saved\n",
    "input_folder = \"C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/article_texts\"\n",
    "\n",
    "# Folder containing stop words files\n",
    "stop_words_folder = \"C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/StopWords\"\n",
    "\n",
    "# Create a function to read stop words from files in the stop words folder\n",
    "def load_stop_words(stop_words_folder):\n",
    "    stop_words = set()\n",
    "\n",
    "    for root, _, files in os.walk(stop_words_folder):\n",
    "        for file in files:\n",
    "            with open(os.path.join(root, file), 'r') as stop_words_file:\n",
    "                stop_words.update(stop_words_file.read().splitlines())\n",
    "\n",
    "    return stop_words\n",
    "\n",
    "# Load stop words from the stop words folder\n",
    "stop_words = load_stop_words(stop_words_folder)\n",
    "\n",
    "# Create a function to clean and perform sentiment analysis on a text\n",
    "def analyze_sentiment(text, stop_words):\n",
    "    # Split the text into words\n",
    "    words = text.split()\n",
    "\n",
    "    # Remove stop words from the text\n",
    "    cleaned_words = [word for word in words if word.lower() not in stop_words]\n",
    "    cleaned_text = ' '.join(cleaned_words)\n",
    "\n",
    "    text_blob = TextBlob(cleaned_text)\n",
    "\n",
    "    # Get sentiment polarity and subjectivity\n",
    "    #sentiment_polarity = text_blob.sentiment.polarity\n",
    "    #sentiment_subjectivity = text_blob.sentiment.subjectivity\n",
    "    # Get the specified variables\n",
    "    positive_score = len([sentence for sentence in text_blob.sentences if sentence.sentiment.polarity > 0])\n",
    "    negative_score = len([sentence for sentence in text_blob.sentences if sentence.sentiment.polarity < 0])\n",
    "    polarity_score = text_blob.sentiment.polarity\n",
    "    subjectivity_score = text_blob.sentiment.subjectivity\n",
    "    avg_sentence_length = len(text_blob.words) / len(text_blob.sentences)\n",
    "    percentage_of_complex_words = len([word for word in text_blob.words if len(word) > 6]) / len(text_blob.words)\n",
    "    fog_index = 0.4 * (avg_sentence_length + percentage_of_complex_words)\n",
    "    avg_number_of_words_per_sentence = len(text_blob.words) / len(text_blob.sentences)\n",
    "    complex_word_count = len([word for word in text_blob.words if len(word) > 6])\n",
    "    word_count = len(text_blob.words)\n",
    "    syllable_per_word = word_count / complex_word_count  # You may need to implement a syllable count function\n",
    "    personal_pronouns = len([word for word in text_blob.words if word.lower() in [\"i\", \"me\", \"my\", \"mine\", \"myself\", \"we\", \"us\", \"our\", \"ours\", \"ourselves\"]])\n",
    "    avg_word_length = sum(len(word) for word in text_blob.words) / word_count\n",
    "\n",
    "    return positive_score,negative_score,polarity_score,subjectivity_score,avg_sentence_length,percentage_of_complex_words,fog_index,avg_number_of_words_per_sentence,complex_word_count,word_count,syllable_per_word,personal_pronouns,avg_word_length\n",
    "\n",
    "# List text files in the input folder\n",
    "text_files = [os.path.join(input_folder, file) for file in os.listdir(input_folder) if file.endswith(\".txt\")]\n",
    "\n",
    "# Perform sentiment analysis on each text file after cleaning\n",
    "#dataframes_list = []\n",
    "result_df = pd.DataFrame()\n",
    "for text_file in text_files:\n",
    "    with open(text_file, 'r', encoding='utf-8') as file:\n",
    "        text_content = file.read()\n",
    "        \n",
    "        positive_score,negative_score,polarity_score,subjectivity_score,avg_sentence_length,percentage_of_complex_words,fog_index,avg_number_of_words_per_sentence,complex_word_count,word_count,syllable_per_word,personal_pronouns,avg_word_length= analyze_sentiment(text_content, stop_words)\n",
    "        filename = os.path.basename(text_file)\n",
    "    # Create a DataFrame for the obtained variables\n",
    "    data = {\n",
    "        'Variable Name': [\n",
    "        'URL_ID',\n",
    "        'POSITIVE SCORE',\n",
    "        'NEGATIVE SCORE',\n",
    "        'POLARITY SCORE',\n",
    "        'SUBJECTIVITY SCORE',\n",
    "        'AVG SENTENCE LENGTH',\n",
    "        'PERCENTAGE OF COMPLEX WORDS',\n",
    "        'FOG INDEX',\n",
    "        'AVG NUMBER OF WORDS PER SENTENCE',\n",
    "        'COMPLEX WORD COUNT',\n",
    "        'WORD COUNT',\n",
    "        'SYLLABLE PER WORD',\n",
    "        'PERSONAL PRONOUNS',\n",
    "        'AVG WORD LENGTH'\n",
    "    ],\n",
    "    'Value': [\n",
    "        filename,\n",
    "        positive_score,\n",
    "        negative_score,\n",
    "        polarity_score,\n",
    "        subjectivity_score,\n",
    "        avg_sentence_length,\n",
    "        percentage_of_complex_words,\n",
    "        fog_index,\n",
    "        avg_number_of_words_per_sentence,\n",
    "        complex_word_count,\n",
    "        word_count,\n",
    "        syllable_per_word,\n",
    "        personal_pronouns,\n",
    "        avg_word_length\n",
    "    ]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    #dataframes_list.append(df)\n",
    "    #print(df)\n",
    "    result_df = pd.concat([df,result_df],ignore_index=True)\n",
    "#print(result_df)  \n",
    "\n",
    "\n",
    "\n",
    "# print(f\"Output saved to {output_file}\")\n",
    "\n",
    "#     print(f\"Sentiment analysis for {filename}:\")\n",
    "#     #print(f\"Polarity: {sentiment_polarity}\")\n",
    "#     #print(f\"Subjectivity: {sentiment_subjectivity}\")\n",
    "#     print(\"POSITIVE SCORE:\", positive_score)\n",
    "#     print(\"NEGATIVE SCORE:\", negative_score)\n",
    "#     print(\"POLARITY SCORE:\", polarity_score)\n",
    "#     print(\"SUBJECTIVITY SCORE:\", subjectivity_score)\n",
    "#     print(\"AVG SENTENCE LENGTH:\", avg_sentence_length)\n",
    "#     print(\"PERCENTAGE OF COMPLEX WORDS:\", percentage_of_complex_words)\n",
    "#     print(\"FOG INDEX:\", fog_index)\n",
    "#     print(\"AVG NUMBER OF WORDS PER SENTENCE:\", avg_number_of_words_per_sentence)\n",
    "#     print(\"COMPLEX WORD COUNT:\", complex_word_count)\n",
    "#     print(\"WORD COUNT:\", word_count)\n",
    "#     print(\"SYLLABLE PER WORD:\", syllable_per_word)\n",
    "#     print(\"PERSONAL PRONOUNS:\", personal_pronouns)\n",
    "#     print(\"AVG WORD LENGTH:\", avg_word_length)\n",
    "    \n",
    "    \n",
    "    \n",
    "#print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38e64d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable Name</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>URL_ID</td>\n",
       "      <td>9820.8.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POSITIVE SCORE</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NEGATIVE SCORE</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POLARITY SCORE</td>\n",
       "      <td>0.055696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SUBJECTIVITY SCORE</td>\n",
       "      <td>0.48031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AVG SENTENCE LENGTH</td>\n",
       "      <td>8.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PERCENTAGE OF COMPLEX WORDS</td>\n",
       "      <td>0.481781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FOG INDEX</td>\n",
       "      <td>3.449855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AVG NUMBER OF WORDS PER SENTENCE</td>\n",
       "      <td>8.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>COMPLEX WORD COUNT</td>\n",
       "      <td>357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>WORD COUNT</td>\n",
       "      <td>741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SYLLABLE PER WORD</td>\n",
       "      <td>2.07563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PERSONAL PRONOUNS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AVG WORD LENGTH</td>\n",
       "      <td>6.507422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>URL_ID</td>\n",
       "      <td>9359.0.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>POSITIVE SCORE</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NEGATIVE SCORE</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>POLARITY SCORE</td>\n",
       "      <td>0.068991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SUBJECTIVITY SCORE</td>\n",
       "      <td>0.528464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AVG SENTENCE LENGTH</td>\n",
       "      <td>10.77381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Variable Name       Value\n",
       "0                             URL_ID  9820.8.txt\n",
       "1                     POSITIVE SCORE          25\n",
       "2                     NEGATIVE SCORE          17\n",
       "3                     POLARITY SCORE    0.055696\n",
       "4                 SUBJECTIVITY SCORE     0.48031\n",
       "5                AVG SENTENCE LENGTH    8.142857\n",
       "6        PERCENTAGE OF COMPLEX WORDS    0.481781\n",
       "7                          FOG INDEX    3.449855\n",
       "8   AVG NUMBER OF WORDS PER SENTENCE    8.142857\n",
       "9                 COMPLEX WORD COUNT         357\n",
       "10                        WORD COUNT         741\n",
       "11                 SYLLABLE PER WORD     2.07563\n",
       "12                 PERSONAL PRONOUNS           0\n",
       "13                   AVG WORD LENGTH    6.507422\n",
       "14                            URL_ID  9359.0.txt\n",
       "15                    POSITIVE SCORE          22\n",
       "16                    NEGATIVE SCORE          16\n",
       "17                    POLARITY SCORE    0.068991\n",
       "18                SUBJECTIVITY SCORE    0.528464\n",
       "19               AVG SENTENCE LENGTH    10.77381"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3e4f78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c497cc05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable Name</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>URL_ID</td>\n",
       "      <td>9820.8.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POSITIVE SCORE</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NEGATIVE SCORE</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POLARITY SCORE</td>\n",
       "      <td>0.055696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SUBJECTIVITY SCORE</td>\n",
       "      <td>0.48031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Variable Name       Value\n",
       "0              URL_ID  9820.8.txt\n",
       "1      POSITIVE SCORE          25\n",
       "2      NEGATIVE SCORE          17\n",
       "3      POLARITY SCORE    0.055696\n",
       "4  SUBJECTIVITY SCORE     0.48031"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8fde0a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9820.8.txt</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>0.05569561157796452</td>\n",
       "      <td>0.48031045751633994</td>\n",
       "      <td>8.142857142857142</td>\n",
       "      <td>0.4817813765182186</td>\n",
       "      <td>3.4498554077501447</td>\n",
       "      <td>8.142857142857142</td>\n",
       "      <td>357</td>\n",
       "      <td>741</td>\n",
       "      <td>2.0756302521008405</td>\n",
       "      <td>0</td>\n",
       "      <td>6.507422402159245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9359.0.txt</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>0.06899136577708008</td>\n",
       "      <td>0.5284641548927262</td>\n",
       "      <td>10.773809523809524</td>\n",
       "      <td>0.6331491712707182</td>\n",
       "      <td>4.562783478032097</td>\n",
       "      <td>10.773809523809524</td>\n",
       "      <td>573</td>\n",
       "      <td>905</td>\n",
       "      <td>1.5794066317626527</td>\n",
       "      <td>1</td>\n",
       "      <td>7.308287292817679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8897.2.txt</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>0.043034992784992794</td>\n",
       "      <td>0.4302171717171718</td>\n",
       "      <td>8.923076923076923</td>\n",
       "      <td>0.4540229885057471</td>\n",
       "      <td>3.750839964633068</td>\n",
       "      <td>8.923076923076923</td>\n",
       "      <td>316</td>\n",
       "      <td>696</td>\n",
       "      <td>2.2025316455696204</td>\n",
       "      <td>0</td>\n",
       "      <td>6.318965517241379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8435.4.txt</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>0.06047526283240568</td>\n",
       "      <td>0.3929353741496599</td>\n",
       "      <td>16.63888888888889</td>\n",
       "      <td>0.5659432387312187</td>\n",
       "      <td>6.8819328510480435</td>\n",
       "      <td>16.63888888888889</td>\n",
       "      <td>339</td>\n",
       "      <td>599</td>\n",
       "      <td>1.766961651917404</td>\n",
       "      <td>2</td>\n",
       "      <td>7.041736227045075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7973.6.txt</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>0.06047526283240568</td>\n",
       "      <td>0.3929353741496599</td>\n",
       "      <td>16.63888888888889</td>\n",
       "      <td>0.5659432387312187</td>\n",
       "      <td>6.8819328510480435</td>\n",
       "      <td>16.63888888888889</td>\n",
       "      <td>339</td>\n",
       "      <td>599</td>\n",
       "      <td>1.766961651917404</td>\n",
       "      <td>2</td>\n",
       "      <td>7.041736227045075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       URL_ID POSITIVE SCORE NEGATIVE SCORE         POLARITY SCORE  \\\n",
       "0  9820.8.txt             25             17    0.05569561157796452   \n",
       "1  9359.0.txt             22             16    0.06899136577708008   \n",
       "2  8897.2.txt             23             13   0.043034992784992794   \n",
       "3  8435.4.txt             17              8    0.06047526283240568   \n",
       "4  7973.6.txt             17              8    0.06047526283240568   \n",
       "\n",
       "     SUBJECTIVITY SCORE  AVG SENTENCE LENGTH PERCENTAGE OF COMPLEX WORDS  \\\n",
       "0   0.48031045751633994    8.142857142857142          0.4817813765182186   \n",
       "1    0.5284641548927262   10.773809523809524          0.6331491712707182   \n",
       "2    0.4302171717171718    8.923076923076923          0.4540229885057471   \n",
       "3    0.3929353741496599    16.63888888888889          0.5659432387312187   \n",
       "4    0.3929353741496599    16.63888888888889          0.5659432387312187   \n",
       "\n",
       "             FOG INDEX AVG NUMBER OF WORDS PER SENTENCE COMPLEX WORD COUNT  \\\n",
       "0   3.4498554077501447                8.142857142857142                357   \n",
       "1    4.562783478032097               10.773809523809524                573   \n",
       "2    3.750839964633068                8.923076923076923                316   \n",
       "3   6.8819328510480435                16.63888888888889                339   \n",
       "4   6.8819328510480435                16.63888888888889                339   \n",
       "\n",
       "  WORD COUNT    SYLLABLE PER WORD PERSONAL PRONOUNS     AVG WORD LENGTH  \n",
       "0        741   2.0756302521008405                 0   6.507422402159245  \n",
       "1        905   1.5794066317626527                 1   7.308287292817679  \n",
       "2        696   2.2025316455696204                 0   6.318965517241379  \n",
       "3        599    1.766961651917404                 2   7.041736227045075  \n",
       "4        599    1.766961651917404                 2   7.041736227045075  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    df['Value'] = df['Value'].astype(str)\n",
    "    set_size = 14\n",
    "    # Calculate the number of sets based on the DataFrame size and set size\n",
    "    num_sets = len(df)//set_size\n",
    "\n",
    "    # Initialize an empty list to store the concatenated sets\n",
    "    concatenated_sets = []\n",
    "\n",
    "    # Iterate through each set and concatenate the rows\n",
    "    for i in range(num_sets):\n",
    "        start_idx = i * set_size\n",
    "        end_idx = start_idx + set_size\n",
    "        concatenated_set = '_ '.join(df.iloc[start_idx:end_idx]['Value'])\n",
    "        concatenated_sets.append([concatenated_set])\n",
    "\n",
    "    # If there are any remaining rows that don't form a complete set, concatenate them separately\n",
    "    remaining_rows = len(df) % set_size\n",
    "    if remaining_rows > 0:\n",
    "        concatenated_set = '; '.join(df.iloc[num_sets * set_size:]['Value'])\n",
    "        concatenated_sets.append([concatenated_set])\n",
    "\n",
    "    # Create a new DataFrame with the concatenated sets\n",
    "    concatenated_df = pd.DataFrame(concatenated_sets, columns=['Concatenated'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Split the \"Original_Column\" into 14 columns based on the delimiter \"_\"\n",
    "    df_split = concatenated_df['Concatenated'].str.split('_', expand=True)\n",
    "\n",
    "    # Rename the columns\n",
    "df_split.columns = ['URL_ID', 'POSITIVE SCORE', 'NEGATIVE SCORE', 'POLARITY SCORE', 'SUBJECTIVITY SCORE', 'AVG SENTENCE LENGTH', 'PERCENTAGE OF COMPLEX WORDS','FOG INDEX', 'AVG NUMBER OF WORDS PER SENTENCE', 'COMPLEX WORD COUNT', 'WORD COUNT', 'SYLLABLE PER WORD', 'PERSONAL PRONOUNS','AVG WORD LENGTH']\n",
    "df_split.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9ea0e61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_split['URL_ID'] = df_split['URL_ID'].str[:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bc06b7b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9820.8</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>0.05569561157796452</td>\n",
       "      <td>0.48031045751633994</td>\n",
       "      <td>8.142857142857142</td>\n",
       "      <td>0.4817813765182186</td>\n",
       "      <td>3.4498554077501447</td>\n",
       "      <td>8.142857142857142</td>\n",
       "      <td>357</td>\n",
       "      <td>741</td>\n",
       "      <td>2.0756302521008405</td>\n",
       "      <td>0</td>\n",
       "      <td>6.507422402159245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9359.0</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>0.06899136577708008</td>\n",
       "      <td>0.5284641548927262</td>\n",
       "      <td>10.773809523809524</td>\n",
       "      <td>0.6331491712707182</td>\n",
       "      <td>4.562783478032097</td>\n",
       "      <td>10.773809523809524</td>\n",
       "      <td>573</td>\n",
       "      <td>905</td>\n",
       "      <td>1.5794066317626527</td>\n",
       "      <td>1</td>\n",
       "      <td>7.308287292817679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8897.2</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>0.043034992784992794</td>\n",
       "      <td>0.4302171717171718</td>\n",
       "      <td>8.923076923076923</td>\n",
       "      <td>0.4540229885057471</td>\n",
       "      <td>3.750839964633068</td>\n",
       "      <td>8.923076923076923</td>\n",
       "      <td>316</td>\n",
       "      <td>696</td>\n",
       "      <td>2.2025316455696204</td>\n",
       "      <td>0</td>\n",
       "      <td>6.318965517241379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8435.4</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>0.06047526283240568</td>\n",
       "      <td>0.3929353741496599</td>\n",
       "      <td>16.63888888888889</td>\n",
       "      <td>0.5659432387312187</td>\n",
       "      <td>6.8819328510480435</td>\n",
       "      <td>16.63888888888889</td>\n",
       "      <td>339</td>\n",
       "      <td>599</td>\n",
       "      <td>1.766961651917404</td>\n",
       "      <td>2</td>\n",
       "      <td>7.041736227045075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7973.6</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>0.06047526283240568</td>\n",
       "      <td>0.3929353741496599</td>\n",
       "      <td>16.63888888888889</td>\n",
       "      <td>0.5659432387312187</td>\n",
       "      <td>6.8819328510480435</td>\n",
       "      <td>16.63888888888889</td>\n",
       "      <td>339</td>\n",
       "      <td>599</td>\n",
       "      <td>1.766961651917404</td>\n",
       "      <td>2</td>\n",
       "      <td>7.041736227045075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID POSITIVE SCORE NEGATIVE SCORE         POLARITY SCORE  \\\n",
       "0  9820.8             25             17    0.05569561157796452   \n",
       "1  9359.0             22             16    0.06899136577708008   \n",
       "2  8897.2             23             13   0.043034992784992794   \n",
       "3  8435.4             17              8    0.06047526283240568   \n",
       "4  7973.6             17              8    0.06047526283240568   \n",
       "\n",
       "     SUBJECTIVITY SCORE  AVG SENTENCE LENGTH PERCENTAGE OF COMPLEX WORDS  \\\n",
       "0   0.48031045751633994    8.142857142857142          0.4817813765182186   \n",
       "1    0.5284641548927262   10.773809523809524          0.6331491712707182   \n",
       "2    0.4302171717171718    8.923076923076923          0.4540229885057471   \n",
       "3    0.3929353741496599    16.63888888888889          0.5659432387312187   \n",
       "4    0.3929353741496599    16.63888888888889          0.5659432387312187   \n",
       "\n",
       "             FOG INDEX AVG NUMBER OF WORDS PER SENTENCE COMPLEX WORD COUNT  \\\n",
       "0   3.4498554077501447                8.142857142857142                357   \n",
       "1    4.562783478032097               10.773809523809524                573   \n",
       "2    3.750839964633068                8.923076923076923                316   \n",
       "3   6.8819328510480435                16.63888888888889                339   \n",
       "4   6.8819328510480435                16.63888888888889                339   \n",
       "\n",
       "  WORD COUNT    SYLLABLE PER WORD PERSONAL PRONOUNS     AVG WORD LENGTH  \n",
       "0        741   2.0756302521008405                 0   6.507422402159245  \n",
       "1        905   1.5794066317626527                 1   7.308287292817679  \n",
       "2        696   2.2025316455696204                 0   6.318965517241379  \n",
       "3        599    1.766961651917404                 2   7.041736227045075  \n",
       "4        599    1.766961651917404                 2   7.041736227045075  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_split.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ef0ef6f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-telem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>321.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-e-hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2345.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-e-hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4321.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-telem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>432.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-telem...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL\n",
       "0   123.0  https://insights.blackcoffer.com/rise-of-telem...\n",
       "1   321.0  https://insights.blackcoffer.com/rise-of-e-hea...\n",
       "2  2345.0  https://insights.blackcoffer.com/rise-of-e-hea...\n",
       "3  4321.0  https://insights.blackcoffer.com/rise-of-telem...\n",
       "4   432.0  https://insights.blackcoffer.com/rise-of-telem..."
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "44a31dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputdf['URL_ID']=inputdf['URL_ID'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c1ef5961",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.merge(inputdf, df_split, how='left', on='URL_ID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "449270f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-telem...</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>0.043158780163730655</td>\n",
       "      <td>0.36588419830994084</td>\n",
       "      <td>11.037974683544304</td>\n",
       "      <td>0.6410550458715596</td>\n",
       "      <td>4.671611891766346</td>\n",
       "      <td>11.037974683544304</td>\n",
       "      <td>559</td>\n",
       "      <td>872</td>\n",
       "      <td>1.5599284436493739</td>\n",
       "      <td>0</td>\n",
       "      <td>7.689220183486238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>321.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-e-hea...</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>0.05912818662818663</td>\n",
       "      <td>0.6368783068783069</td>\n",
       "      <td>11.708333333333334</td>\n",
       "      <td>0.7295373665480427</td>\n",
       "      <td>4.975148279952551</td>\n",
       "      <td>11.708333333333334</td>\n",
       "      <td>205</td>\n",
       "      <td>281</td>\n",
       "      <td>1.3707317073170733</td>\n",
       "      <td>0</td>\n",
       "      <td>8.12099644128114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2345.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-e-hea...</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>0.05912818662818663</td>\n",
       "      <td>0.6368783068783069</td>\n",
       "      <td>11.708333333333334</td>\n",
       "      <td>0.7295373665480427</td>\n",
       "      <td>4.975148279952551</td>\n",
       "      <td>11.708333333333334</td>\n",
       "      <td>205</td>\n",
       "      <td>281</td>\n",
       "      <td>1.3707317073170733</td>\n",
       "      <td>0</td>\n",
       "      <td>8.12099644128114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4321.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-telem...</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>0.09607299498746869</td>\n",
       "      <td>0.3514755639097744</td>\n",
       "      <td>11.525423728813559</td>\n",
       "      <td>0.6014705882352941</td>\n",
       "      <td>4.850757726819541</td>\n",
       "      <td>11.525423728813559</td>\n",
       "      <td>409</td>\n",
       "      <td>680</td>\n",
       "      <td>1.662591687041565</td>\n",
       "      <td>0</td>\n",
       "      <td>7.227941176470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>432.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-telem...</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>0.09607299498746869</td>\n",
       "      <td>0.3514755639097744</td>\n",
       "      <td>11.525423728813559</td>\n",
       "      <td>0.6014705882352941</td>\n",
       "      <td>4.850757726819541</td>\n",
       "      <td>11.525423728813559</td>\n",
       "      <td>409</td>\n",
       "      <td>680</td>\n",
       "      <td>1.662591687041565</td>\n",
       "      <td>0</td>\n",
       "      <td>7.227941176470588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL POSITIVE SCORE  \\\n",
       "0   123.0  https://insights.blackcoffer.com/rise-of-telem...             21   \n",
       "1   321.0  https://insights.blackcoffer.com/rise-of-e-hea...             12   \n",
       "2  2345.0  https://insights.blackcoffer.com/rise-of-e-hea...             12   \n",
       "3  4321.0  https://insights.blackcoffer.com/rise-of-telem...             29   \n",
       "4   432.0  https://insights.blackcoffer.com/rise-of-telem...             29   \n",
       "\n",
       "  NEGATIVE SCORE         POLARITY SCORE    SUBJECTIVITY SCORE  \\\n",
       "0             20   0.043158780163730655   0.36588419830994084   \n",
       "1              5    0.05912818662818663    0.6368783068783069   \n",
       "2              5    0.05912818662818663    0.6368783068783069   \n",
       "3              7    0.09607299498746869    0.3514755639097744   \n",
       "4              7    0.09607299498746869    0.3514755639097744   \n",
       "\n",
       "   AVG SENTENCE LENGTH PERCENTAGE OF COMPLEX WORDS           FOG INDEX  \\\n",
       "0   11.037974683544304          0.6410550458715596   4.671611891766346   \n",
       "1   11.708333333333334          0.7295373665480427   4.975148279952551   \n",
       "2   11.708333333333334          0.7295373665480427   4.975148279952551   \n",
       "3   11.525423728813559          0.6014705882352941   4.850757726819541   \n",
       "4   11.525423728813559          0.6014705882352941   4.850757726819541   \n",
       "\n",
       "  AVG NUMBER OF WORDS PER SENTENCE COMPLEX WORD COUNT WORD COUNT  \\\n",
       "0               11.037974683544304                559        872   \n",
       "1               11.708333333333334                205        281   \n",
       "2               11.708333333333334                205        281   \n",
       "3               11.525423728813559                409        680   \n",
       "4               11.525423728813559                409        680   \n",
       "\n",
       "     SYLLABLE PER WORD PERSONAL PRONOUNS     AVG WORD LENGTH  \n",
       "0   1.5599284436493739                 0   7.689220183486238  \n",
       "1   1.3707317073170733                 0    8.12099644128114  \n",
       "2   1.3707317073170733                 0    8.12099644128114  \n",
       "3    1.662591687041565                 0   7.227941176470588  \n",
       "4    1.662591687041565                 0   7.227941176470588  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1ff5aa18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 14)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_split.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5836b0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"C:/Users/vaish/Downloads/NLP_Artifacts/NLP_Artifacts/OutputDataStructureee.xlsx\"\n",
    "final_df.to_excel(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e8c52ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting docx2txt\n",
      "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
      "Building wheels for collected packages: docx2txt\n",
      "  Building wheel for docx2txt (setup.py): started\n",
      "  Building wheel for docx2txt (setup.py): finished with status 'done'\n",
      "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3980 sha256=c588eff4904f59202d3ceea10da2403eafc764db0aee081fd770b9e2dc8ae6ed\n",
      "  Stored in directory: c:\\users\\vaish\\appdata\\local\\pip\\cache\\wheels\\40\\75\\01\\e6c444034338bde9c7947d3467807f889123465c2371e77418\n",
      "Successfully built docx2txt\n",
      "Installing collected packages: docx2txt\n",
      "Successfully installed docx2txt-0.8\n"
     ]
    }
   ],
   "source": [
    "!pip install docx2txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c028083a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.17.1-py2.py3-none-any.whl (636 kB)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\vaish\\anaconda3\\lib\\site-packages (from textblob) (3.6.5)\n",
      "Requirement already satisfied: click in c:\\users\\vaish\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (8.0.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\vaish\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\vaish\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\vaish\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\vaish\\anaconda3\\lib\\site-packages (from click->nltk>=3.1->textblob) (0.4.4)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.17.1\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
